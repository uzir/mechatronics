import streamlit as st
import google.generativeai as genai
import PyPDF2
from PIL import Image
from pptx import Presentation
from pptx.util import Inches, Pt
from pptx.enum.text import PP_ALIGN
import io

# --- ×¤×•× ×§×¦×™×•×ª ×¢×–×¨ ---

@st.cache_data
def load_knowledge_base(file_path):
    """×§×•×¨××ª ×ª×•×›×Ÿ ××§×•×‘×¥ PDF ×•××—×–×™×¨×” ××•×ª×• ×›×˜×§×¡×˜."""
    try:
        with open(file_path, "rb") as pdf_file:
            pdf_reader = PyPDF2.PdfReader(pdf_file)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text()
            return text
    except FileNotFoundError:
        return None
    except Exception as e:
        st.error(f"×©×’×™××” ×‘×§×¨×™××ª ×§×•×‘×¥ ×”-PDF: {e}")
        return None

def create_presentation_from_text(text_content):
    """×™×•×¦×¨×ª ××¦×’×ª PowerPoint ×¢×œ ×‘×¡×™×¡ ×˜×§×¡×˜ ×‘×¤×•×¨××˜ Markdown."""
    prs = Presentation()
    slides_text = text_content.strip().split("\n\n")

    TITLE_AND_CONTENT_LAYOUT = 1
    TITLE_ONLY_LAYOUT = 5

    for slide_text in slides_text:
        lines = slide_text.strip().split('\n')
        if not lines or not lines[0]: continue

        title = lines[0].replace("#", "").strip()
        content_points = [line.replace("-", "").strip() for line in lines[1:] if line.strip().startswith("-")]

        if content_points:
            slide_layout = prs.slide_layouts[TITLE_AND_CONTENT_LAYOUT]
            slide = prs.slides.add_slide(slide_layout)
            content_shape = slide.shapes.placeholders[1]
            tf = content_shape.text_frame
            tf.clear()
            for point in content_points:
                p = tf.add_paragraph()
                p.text = point
                p.alignment = PP_ALIGN.RIGHT
                p.font.size = Pt(20)
                p.level = 0
        else:
            slide_layout = prs.slide_layouts[TITLE_ONLY_LAYOUT]
            slide = prs.slides.add_slide(slide_layout)
        
        title_shape = slide.shapes.title
        title_shape.text = title
        title_paragraph = title_shape.text_frame.paragraphs[0]
        title_paragraph.alignment = PP_ALIGN.RIGHT
        title_paragraph.font.size = Pt(36)
            
    bio = io.BytesIO()
    prs.save(bio)
    return bio.getvalue()

def get_response_text(response):
    """
    ×¤×•× ×§×¦×™×” ×—×¡×™× ×” ×œ×—×™×œ×•×¥ ×˜×§×¡×˜ ×××•×‘×™×™×§×˜ ×”×ª×’×•×‘×” ×©×œ ×”××•×“×œ.
    ×× ×¡×” ××ª ×”×’×™×©×” ×”×¡×˜× ×“×¨×˜×™×ª (.text) ×•×× × ×›×©×œ×ª, ×× ×¡×” ×’×™×©×ª ×’×™×‘×•×™.
    """
    try:
        # ×”×“×¨×š ×”×¡×˜× ×“×¨×˜×™×ª ×•×”××•×¢×“×¤×ª
        return response.text
    except Exception:
        # ×“×¨×š ×’×™×‘×•×™ ×œ××§×¨×” ×©×œ ××‘× ×” ××•×‘×™×™×§×˜ ×©×•× ×” ××• ×’×¨×¡×” ×™×©× ×”
        try:
            return response.parts[0].text
        except Exception as e:
            st.error(f"×©×’×™××” ×§×¨×™×˜×™×ª: ×œ× × ×™×ª×Ÿ ×œ×—×œ×¥ ×˜×§×¡×˜ ×××•×‘×™×™×§×˜ ×”×ª×’×•×‘×”. {e}")
            st.write(response) # ×”×¦×’×ª ×”××•×‘×™×™×§×˜ ×”××œ× ×œ×¦×•×¨×›×™ ×“×™×‘××’
            return "×©×’×™××” ×‘×”×¦×’×ª ×”×ª×’×•×‘×”."

# --- ×”×’×“×¨×•×ª ×•×”×•×¨××•×ª ×œ×‘×•×˜ ---

knowledge_base_text = load_knowledge_base("819387ALL.pdf")
BASE_SYSTEM_INSTRUCTION = """
××ª×” ××•×¨×” ××•××—×” ×‘××’××•×ª ××›×˜×¨×•× ×™×§×” (×›×™×ª×•×ª ×™â€“×™"×‘) ×¢× ×©×œ×•×©×” ××¦×‘×™×...
(×”×”× ×—×™×•×ª ×©×œ×š × ×©××¨×•×ª ×›×¤×™ ×©×”×Ÿ)
"""
if knowledge_base_text:
    SYSTEM_INSTRUCTION = f"{BASE_SYSTEM_INSTRUCTION}\n\n---×××’×¨ ×™×“×¢ ×§×‘×•×¢---\n{knowledge_base_text}\n---"
else:
    SYSTEM_INSTRUCTION = BASE_SYSTEM_INSTRUCTION

PAGE_TITLE = "ğŸ¤– ×”××•×¨×” ×œ××›×˜×¨×•× ×™×§×”"
st.set_page_config(page_title=PAGE_TITLE, page_icon="ğŸ¤–", layout="wide")
st.markdown("""<style> body { direction: rtl; } .stTextInput > div > div > input { direction: rtl; } </style>""", unsafe_allow_html=True)
st.title(PAGE_TITLE)

try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    chat_model = genai.GenerativeModel(model_name="gemini-1.5-pro-latest", system_instruction=SYSTEM_INSTRUCTION, tools=['google_search_retrieval'])
    basic_model = genai.GenerativeModel(model_name="gemini-1.5-pro-latest")
except Exception as e:
    st.error("×©×’×™××” ×‘×”×’×“×¨×ª ×”-API Key. ×× × ×•×“× ×©×”×•×¡×¤×ª ××•×ª×• ×›×¨××•×™ ×‘'×¡×•×“×•×ª' ×”××¤×œ×™×§×¦×™×”.", icon="ğŸš¨")
    st.stop()

tabs = st.tabs(["ğŸ’¬ ×¦'××˜ ×¢× ×”×‘×•×˜", "ğŸ–¼ï¸ × ×™×ª×•×— ×ª××•× ×•×ª", "ğŸ§  ××—×•×œ×œ ××‘×—× ×™×", "ğŸ“Š ××—×•×œ×œ ××¦×’×•×ª"])

# --- ×˜××‘ 1: ×¦'××˜ ×¨×’×™×œ ---
with tabs[0]:
    st.header("×©×™×—×” ×¢× ×”××•×¨×” ×œ××›×˜×¨×•× ×™×§×”")
    # (×§×•×“ ×”×¦'××˜ × ×©××¨ ×œ×œ× ×©×™× ×•×™)
    if "chat" not in st.session_state:
        st.session_state.chat = chat_model.start_chat(history=[])
        st.session_state.messages = [{"role": "assistant", "content": "×©×œ×•×, ×× ×™ ×”××•×¨×” ×”×“×™×’×™×˜×œ×™ ×œ××›×˜×¨×•× ×™×§×”. ××™×š ××•×›×œ ×œ×¢×–×•×¨?"}]
    for message in st.session_state.get("messages", []):
        with st.chat_message(message["role"]):
            st.markdown(f'<div style="direction: rtl;">{message["content"]}</div>', unsafe_allow_html=True)
    if prompt := st.chat_input("×›×ª×‘×• ×›××Ÿ ××ª ×©××œ×ª×›×..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(f'<div style="direction: rtl;">{prompt}</div>', unsafe_allow_html=True)
        with st.chat_message("assistant"):
            with st.spinner("×—×•×©×‘..."):
                response_stream = st.session_state.chat.send_message(prompt, stream=True)
                full_response = st.write_stream(response_stream)
        st.session_state.messages.append({"role": "assistant", "content": full_response})

# --- ×˜××‘ 2: × ×™×ª×•×— ×ª××•× ×•×ª ---
with tabs[1]:
    st.header("× ×™×ª×•×— ×©×¨×˜×•×˜×™× ×•×ª××•× ×•×ª")
    uploaded_image = st.file_uploader("×‘×—×¨ ×§×•×‘×¥ ×ª××•× ×”", type=["png", "jpg", "jpeg"], key="analyzer")
    image_prompt = st.text_input("××” ×ª×¨×¦×” ×œ×©××•×œ ×¢×œ ×”×ª××•× ×”?", key="image_q")
    if st.button("× ×ª×— ××ª ×”×ª××•× ×”", key="analyze_btn"):
        if uploaded_image and image_prompt:
            with st.spinner("××¢×‘×“ ××ª ×”×ª××•× ×”..."):
                image_obj = Image.open(uploaded_image)
                response = basic_model.generate_content([image_prompt, image_obj])
                st.subheader("×ª×•×¦××•×ª ×”× ×™×ª×•×—:")
                # ×©×™××•×© ×‘×¤×•× ×§×¦×™×” ×”×—×¡×™× ×” ×œ×—×™×œ×•×¥ ×”×˜×§×¡×˜
                response_text = get_response_text(response)
                st.markdown(f'<div style="direction: rtl;">{response_text}</div>', unsafe_allow_html=True)
        else:
            st.warning("×× × ×”×¢×œ×” ×ª××•× ×” ×•×›×ª×•×‘ ×©××œ×”.")

# --- ×˜××‘ 3: ××—×•×œ×œ ××‘×—× ×™× ---
with tabs[2]:
    st.header("××—×•×œ×œ ××‘×—× ×™× ×•×—×™×“×•× ×™×")
    with st.form("quiz_form"):
        quiz_topic = st.text_input("× ×•×©× ×”××‘×—×Ÿ")
        num_questions = st.number_input("××¡×¤×¨ ×©××œ×•×ª", min_value=1, max_value=20, value=5)
        question_type = st.selectbox("×¡×•×’ ×”×©××œ×•×ª", ["×¨×‘-×‘×¨×™×¨×ª×™×•×ª (×××¨×™×§××™×•×ª)", "×¤×ª×•×—×•×ª", "× ×›×•×Ÿ / ×œ× × ×›×•×Ÿ"])
        submitted = st.form_submit_button("ğŸš€ ×¦×•×¨ ××ª ×”××‘×—×Ÿ")
    if submitted and quiz_topic:
        with st.spinner("××›×™×Ÿ ××‘×—×Ÿ..."):
            quiz_prompt = f"×¦×•×¨ ××‘×—×Ÿ ×‘× ×•×©× {quiz_topic}, ×¢× {num_questions} ×©××œ×•×ª ××¡×•×’ {question_type}."
            response = basic_model.generate_content(quiz_prompt)
            st.subheader(f"××‘×—×Ÿ ×‘× ×•×©×: {quiz_topic}")
            # ×©×™××•×© ×‘×¤×•× ×§×¦×™×” ×”×—×¡×™× ×” ×œ×—×™×œ×•×¥ ×”×˜×§×¡×˜
            response_text = get_response_text(response)
            st.markdown(f'<div style="direction: rtl;">{response_text}</div>', unsafe_allow_html=True)

# --- ×˜××‘ 4: ××—×•×œ×œ ××¦×’×•×ª ---
with tabs[3]:
    st.header("××—×•×œ×œ ××¦×’×•×ª PowerPoint")
    with st.form("ppt_form"):
        ppt_topic = st.text_input("× ×•×©× ×”××¦×’×ª")
        slide_count = st.number_input("××¡×¤×¨ ×©×§×•×¤×™×•×ª", min_value=3, max_value=20, value=7)
        target_audience = st.text_input("×§×”×œ ×™×¢×“")
        submitted = st.form_submit_button("ğŸ“Š ×¦×•×¨ ××¦×’×ª")
    if submitted and ppt_topic:
        with st.spinner("×›×•×ª×‘ ××ª ×ª×•×›×Ÿ ×”××¦×’×ª..."):
            ppt_prompt = f"×¦×•×¨ ×ª×•×›×Ÿ ×œ××¦×’×ª ×©×œ {slide_count} ×©×§×•×¤×™×•×ª ×‘× ×•×©× '{ppt_topic}' ×œ×§×”×œ ×™×¢×“ ×©×œ '{target_audience}'. ×”×—×–×¨ ×‘×¤×•×¨××˜ Markdown..."
            response = basic_model.generate_content(ppt_prompt)
            # ×©×™××•×© ×‘×¤×•× ×§×¦×™×” ×”×—×¡×™× ×” ×œ×—×™×œ×•×¥ ×”×˜×§×¡×˜
            presentation_text = get_response_text(response)
        with st.spinner("×‘×•× ×” ××ª ×§×•×‘×¥ ×”-PowerPoint..."):
            ppt_file_data = create_presentation_from_text(presentation_text)
        st.success("×”××¦×’×ª ×©×œ×š ××•×›× ×” ×œ×”×•×¨×“×”!")
        st.download_button(label="ğŸ“¥ ×”×•×¨×“ ××ª ×”××¦×’×ª (.pptx)", data=ppt_file_data, file_name=f"{ppt_topic}.pptx")
        with st.expander("×”×¦×’ ××ª ×”×ª×•×›×Ÿ ×”×˜×§×¡×˜×•××œ×™ ×©×œ ×”××¦×’×ª"):
            st.markdown(f'<div style="direction: rtl; text-align: right;">{presentation_text}</div>', unsafe_allow_html=True)
    elif submitted:
        st.warning("×× × ××œ× ××ª × ×•×©× ×”××¦×’×ª.")
